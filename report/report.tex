\documentclass[11pt]{article}
\usepackage[paper=letterpaper,margin=1in]{geometry}
\usepackage{graphics}
\usepackage{epsfig}
\usepackage{arcs}
\usepackage{fontenc}
\usepackage{alltt}
\usepackage{amssymb,amsfonts,epsf,url}
\usepackage{graphicx}
\usepackage{pstricks,pstricks-add}
\usepackage{pst-node}
\usepackage{pst-coil}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{verbatim}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{pstricks,pstricks-add,xcolor}
\usepackage{pst-node}
\usepackage{pst-coil}
\usepackage{tikz}
\usepackage{tabu}
\usepackage{multirow}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{observation}{Observation}
\newtheorem{case}[theorem]{Case}
\newtheorem{subcase}[theorem]{SubCase}
\newtheorem{transrule}[theorem]{TransRule}
\newtheorem{branchrule}[theorem]{BranchRule}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{assumption}[theorem]{Assumption}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{fact}[theorem]{Fact}
\newtheorem{reduction}{Reduction Rules}[section]
\renewcommand{\labelenumi}{\arabic{enumi}.}
\renewcommand{\labelenumii}{\arabic{enumi}.\arabic{enumii}.}
\renewcommand{\labelenumiii}{\arabic{enumi}.\arabic{enumii}.\arabic{enumiii}.}
\renewcommand{\labelenumiv}{\arabic{enumi}.\arabic{enumii}.\arabic{enumiii}.\arabic{enumiv}.}
\newlength{\alginputwidth}
\newlength{\algboxwidth}
\newcommand{\alginput}[1]{\makebox[1.5cm][l]{ {\sc Input:}} \parbox[t]{\alginputwidth}{{\it #1}}}
\newcommand{\algoutput}[1]{\makebox[1.5cm][l]{ {\sc Output:}} \parbox[t]{\alginputwidth}{{\it #1}}}
\newcommand{\algtitle}[1]{\underline{Algorithm \ {\bf #1}} \vspace*{1mm}\\}
\newcommand{\inlinecode}{\texttt}
\newsavebox{\algbox}
\newsavebox{\captionbox}
\newenvironment{algorithm}[2]%
    {
        \setlength{\algboxwidth}{\columnwidth}
        \addtolength{\algboxwidth}{-\columnsep}
        \addtolength{\algboxwidth}{-1mm}
        \setlength{\alginputwidth}{\algboxwidth}
        \addtolength{\alginputwidth}{-1.7cm}
        \begin{figure}[tb]
            \vspace*{2mm}
            \centering
            \begin{lrbox}{\captionbox}
                \begin{minipage}[b]{\algboxwidth}
                    \centering
                    \caption{#1}
                    \label{#2}
                \end{minipage}
            \end{lrbox}
            \begin{lrbox}{\algbox}
                \begin{minipage}[b]{\algboxwidth}
                    \footnotesize
                    \vspace*{2mm}
    } % end of begin
    {
                    \vspace*{0.2mm}
               \end{minipage}
            \end{lrbox}
            \fbox{\usebox{\algbox}\hspace*{1mm}}
            \usebox{\captionbox}
            \vspace*{-4mm}
        \end{figure}
    }
\newsavebox{\algcodebox}
\newenvironment{codeblock}%
    {
        \begin{enumerate}
            \setlength{\itemsep}{2pt}
            \setlength{\parsep}{0pt}
            \setlength{\topsep}{0pt}
            \setlength{\parskip}{0pt}
            \setlength{\partopsep}{0pt}
    } % end of begin
    {\end{enumerate}}
\newcommand{\step}{\item}
\newcommand{\paramproblem}[4]{\noindent {\sc #1}
\\
{\bf Given:} #2\\
{\bf Parameter:} #3\\
{\bf Question:} #4}


\newcommand{\YES}{\textup{\textsf{YES}}}
\newcommand{\NO}{\textup{\textsf{NO}}}
\newcommand{\Oh}{{\mathcal O}}
\newcommand{\nat}{\mathbb{N}}

\newcommand{\Pol}{\mbox{$\mathcal P$}}
\newcommand{\NP}{\mbox{$\mathcal{NP}$}}

\def\eg{{\em e.g.}}
\def\cf{{\em cf.}}
\def\ie{{\em i.e.}}
\def\etal{{\em et al.}}



\psset{unit=1pt}

\date{16 March 2017}
\title{Benchmarking Inductive Monopolar Recognition}

\author{{\sc Nathaniel Brengle}\thanks{Address of Author 1. Email: {\tt nathaniel.brengle@gmail.com}}}


\begin{document}

\maketitle

\begin{abstract}
Following Kanj \textit{et al.} \cite{ref1} we implement and benchmark \textsc{Inductive Monopolar Recognition} and a compare its performance to a general \textsc{$\Pi_A,$$\Pi_B$-Recognition} branching algorithm also described by Kanj \textit{et al.}. The two algorithms have the same runtime, $2^{\Oh(k)}n^{\Oh(1)}$. Given that the two algorithms each solve the probem of \textsc{Monopolar Recognition} in the same runtime, a benchmark comparison of the two algorithms is a pertinent investigation of their practicality.

\end{abstract}

\pagenumbering{roman}
\pagenumbering{arabic}


\section{Introduction}
\label{sec:intro}

\subsection{Motivation and related work}
\label{subsec:motive}
Motivate your work, and review the related work in the literature.

\subsection{Results and techniques}
\label{subsec:results}
The algorithms were implemented in Python 2.7.13 as its a widely used language with a simple type structure strong language-native analysis tools. The executions were benchmarked on a MacBook Pro(Mid 2015) with a 2.8 GHz Intl Core i7 processor and 16 GB 1600 MHz DDR3 Memory. Rather than embrace fully idiomatic Python, several "non-Pythonic" implementations were made for readability. The full source code is available: \url{https://github.com/nbrengle/monopolar_partition/} and pull requests are welcome.

Rather than re-invent the wheel for graph processing, an established scientific graph-theory library was used to handle the graph data structure(s): \inlinecode{NetworkX} v1.11. NetworkX uses dictionaries-of-dictionaries as the underlying structure of graphs, allowing for constant-time retrieval, as well as trivial iteration and introspection. Though \inlinecode{NetworkX} allows for arbitary node values, sequential integer values are used throughout for simplicity.

A set of five graphs of orders ranging from six to 20 were used as benchmarks for the correctness as well as the benchmark. Varying values for \textit{k} were employed on each graph to allow for both intra-graph and inter-graph execution comparison. The \inlinecode{time.time()} module was employed to measure the execution time. This module is the canonical methodology for measuring processor time in Python 2.7.13 on Unix-based architectures. Each combination of graph and parameter value was executed in sets of three consisting of 100 executions. The lowest average time of the three sets was used as the benchmark for that particular graph-parameter combination.

Additionally results from the Python profiling module \inlinecode{cProfile} are included for the execution on one graph-parameter combination per graph to demonstrate the relative time consumed on a per caller basis. The \inlinecode{cProfile} time results have only hundredths-of-a-second resolution making them undescriptive for single executions of the algorithms. The results obtained are instead for a full set of 300 executions per graph. Rather than average these values, we include them raw as their primary benefit is for the demonstration of the relative computational intensity of the different steps rather than substatively indicative of the performance of the algorithm as a whole. The \inlinecode{cProfile} results have been cleaned, removing system callers from the call list as the profiling data is illustrative rather than substantive. The raw results are available with the source code.

\section{Preliminaries}
\label{sec:prelim}
We follow standard notation for graph-theory. Let \textit{G} be a graph; its set of vertices is denoted \textit{V(G)} and its set of edges \textit{E(G)}. The \textit{order} of a graph is $\mid\textit{V(G)}\mid$ and represented throughout by \textit{n}. $\mid\textit{E(G)}\mid$ is denoted throughout by \textit{m}. A subgraph induced in \textit{G} by $\textit{X}\subseteq\textit{V(G)}$ is denoted \textit{G[X]}. For any set \textit{S} of verticies in \textit{G} we denote the subgraph of \textit{G} obtained by deleting all the vertices in \textit{S} and their incident edges as \textit{G \em S}. For a vertex $\textit{v}\in{V(G)}$ we use \textit{G \em v} for \textit{G \em \{v\}}. We denote a simple path on 3 vertices with \textit{$P_3$}.

%here I would continue to jack stuff from Kanj, but I don't care I need some substance which I totally lack. Alright. Let's do this.

\section{Graphs Employed}
\label{subsec:graphs}

\begin{center}
    \begin{tabu} to 0.8\textwidth { | X[l] X[c] X[c] X[c] X[c] | }
        \hline
        Nick-Name & $\mid\textit{V(G)}\mid$ & Edges & Monopolar Partition & Vertex \\
        [0.5ex]
        \hline
        \hline
        Bowtie & 6 & (1, 2), (2, 3), (3, 1), (3, 4), (4, 5), (5, 6), (6, 4) & [1, 2, 5, 6], [3] & 4 \\
        [0.3ex]
        \hline
        $K_3$ and Claw & 6 & (1, 2), (2, 3), (3, 4), (3, 5), (3, 6), (1, 3) & [1, 2], [4, 5, 6] & 3 \\
        [0.3ex]
        \hline
        $K_5$ and Claw & 8 & (1, 2), (1, 3), (1, 4), (1, 5), (2, 3), (2, 4), (2, 5), (3, 4), (3, 5), (4, 5), (5, 6), (5, 7), (5, 8) & [0, 1, 2, 3], [5, 6, 7] & 4 \\
        [0.3ex]
        \hline
        From 3.1 & 10 & (1, 2), (2, 3), (2, 4), (2, 5), (3, 5), (3, 4), (4, 6), (6, 7), (7, 10), (7, 9), (7, 8), (8, 9), (9, 10) & [2, 3, 5, 6,9, 10], [1, 4, 8] & 7 \\
        [0.3ex]
        \hline
        Twenty & 20 & (1, 6), (1, 4), (2, 7), (3, 8), (3, 9), (3, 4), (3, 13), (4, 14), (4, 5), (5, 10), (6, 12), (7, 8), (8, 9), (8, 13), (9, 13), (9, 14), (10, 14), (11, 5), (11, 15), (10, 15), (10, 11), (5, 15), (14, 18), (14, 19), (15, 19), (15, 20), (17, 18), (12, 17), (12, 18), (19, 20) & [1, 2, 3, 5, 8, 9, 10, 11, 12, 13, 17, 18, 19, 20], [4, 6, 7, 15, 16] & 14 \\
        [0.3ex]
        \hline
    \end{tabu}
\end{center}

\section{Benchmarks for \textsc{Inductive Monopolar Recognition}}
\label{subsec:structural}

\subsection{}
\label{subsec:results} %duplicate be careful
\begin{center}
    \begin{tabu} to 0.8\textwidth { | X[l] X[l] X[c] X[c] | }
        \hline
        Graph & Time (Sec) & K & Result \\
        [0.5ex]
        \hline
        \hline
Bowtie & 0.000813608169556 & 1 & False \\
[0.3ex]
  & 0.00289664983749 & 2 & True \\
[0.3ex]
\hline
$K_3$ and Claw & 0.000661911964417 & 1 & True \\
[0.3ex]
 & 0.000688810348511 & 2 & True \\
[0.3ex]
\hline
$K_5$ and Claw & 0.00292824029922 & 1 & True \\
[0.3ex]
 & 0.00294578075409 & 2 & True \\
[0.3ex]
\hline
From 3.1 & 0.00161388158798 & 1 & True \\
[0.3ex]
 & 0.00398640155792 & 2 & True \\
[0.3ex]
 & 0.0047345495224 & 3 & True \\
[0.3ex]
\hline
Twenty & 0.0853665113449 & 3 & False \\
[0.3ex]
  & 0.265883820057 & 5 & True \\
[0.3ex]
 & 0.288087880611 & 7 & True \\
[0.3ex]
\hline
\end{tabu}
\end{center}

\subsection{}
\label{subsec:results} %duplicate be careful

==== Case Bowtie ====
    528677 function calls (528676 primitive calls) in 0.377 seconds

   Ordered by: standard name

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
     2409    0.002    0.000    0.002    0.000 ind-rec.py:124(reduction_rule_5_2)
     2408    0.007    0.000    0.012    0.000 ind-rec.py:166(reduction_rule_5_3)
     2408    0.011    0.000    0.019    0.000 ind-rec.py:220(branching_rule_5_1)
     2408    0.010    0.000    0.082    0.000 ind-rec.py:289(branching_rule_5_2)
     5418    0.007    0.000    0.262    0.000 ind-rec.py:347(reduction_rule_loop)
      301    0.011    0.000    0.374    0.001 ind-rec.py:374(inductive_recognition)
     7827    0.019    0.000    0.042    0.000 ind-rec.py:40(p3_free)
        1    0.002    0.002    0.377    0.377 ind-rec.py:421(case_bowtie)
     5419    0.017    0.000    0.118    0.000 ind-rec.py:6(cluster_size)
     5419    0.008    0.000    0.144    0.000 ind-rec.py:67(valid_cluster_graph)
     5419    0.012    0.000    0.241    0.000 ind-rec.py:79(reduction_rule_5_1)

     ==== Case k3 + Claw ====
              469094 function calls in 0.329 seconds

        Ordered by: standard name

        ncalls  tottime  percall  cumtime  percall filename:lineno(function)
          2707    0.002    0.000    0.002    0.000 ind-rec.py:124(reduction_rule_5_2)
          2704    0.005    0.000    0.008    0.000 ind-rec.py:166(reduction_rule_5_3)
          2704    0.005    0.000    0.008    0.000 ind-rec.py:220(branching_rule_5_1)
          2704    0.007    0.000    0.050    0.000 ind-rec.py:289(branching_rule_5_2)
          3606    0.006    0.000    0.200    0.000 ind-rec.py:347(reduction_rule_loop)
           301    0.012    0.000    0.328    0.001 ind-rec.py:374(inductive_recognition)
          6313    0.014    0.000    0.029    0.000 ind-rec.py:40(p3_free)
             1    0.001    0.001    0.329    0.329 ind-rec.py:443(case_k3_plus_claw)
          4811    0.013    0.000    0.106    0.000 ind-rec.py:6(cluster_size)
          4811    0.007    0.000    0.133    0.000 ind-rec.py:67(valid_cluster_graph)
          3609    0.009    0.000    0.184    0.000 ind-rec.py:79(reduction_rule_5_1)
          ==== Case k5 + Claw ====
                   2017852 function calls in 1.322 seconds

             Ordered by: standard name

             ncalls  tottime  percall  cumtime  percall filename:lineno(function)
               6014    0.005    0.000    0.005    0.000 ind-rec.py:124(reduction_rule_5_2)
               6011    0.036    0.000    0.062    0.000 ind-rec.py:166(reduction_rule_5_3)
               6011    0.031    0.000    0.053    0.000 ind-rec.py:220(branching_rule_5_1)
               6011    0.020    0.000    0.321    0.000 ind-rec.py:289(branching_rule_5_2)
               9016    0.016    0.000    0.827    0.000 ind-rec.py:347(reduction_rule_loop)
                301    0.028    0.000    1.319    0.004 ind-rec.py:374(inductive_recognition)
              15030    0.181    0.000    0.364    0.000 ind-rec.py:40(p3_free)
                  1    0.003    0.003    1.322    1.322 ind-rec.py:464(case_k5_plus_claw)
              10823    0.036    0.000    0.363    0.000 ind-rec.py:6(cluster_size)
              10823    0.020    0.000    0.562    0.000 ind-rec.py:67(valid_cluster_graph)
               9019    0.025    0.000    0.743    0.000 ind-rec.py:79(reduction_rule_5_1)

               ==== Case From 3.1 ====
                        2636229 function calls in 1.845 seconds

                  Ordered by: standard name

                  ncalls  tottime  percall  cumtime  percall filename:lineno(function)
                   10820    0.008    0.000    0.009    0.000 ind-rec.py:124(reduction_rule_5_2)
                   10817    0.043    0.000    0.072    0.000 ind-rec.py:166(reduction_rule_5_3)
                    8411    0.043    0.000    0.071    0.000 ind-rec.py:220(branching_rule_5_1)
                    8410    0.032    0.000    0.405    0.000 ind-rec.py:289(branching_rule_5_2)
                   15018    0.030    0.000    1.256    0.000 ind-rec.py:347(reduction_rule_loop)
                     301    0.045    0.000    1.839    0.006 ind-rec.py:374(inductive_recognition)
                   25837    0.154    0.000    0.312    0.000 ind-rec.py:40(p3_free)
                       1    0.005    0.005    1.845    1.845 ind-rec.py:485(case_from_3_1)
                   18630    0.073    0.000    0.576    0.000 ind-rec.py:6(cluster_size)
                   18630    0.033    0.000    0.754    0.000 ind-rec.py:67(valid_cluster_graph)
                   17427    0.047    0.000    1.145    0.000 ind-rec.py:79(reduction_rule_5_1)
                   ==== Case 20 ====
                            179986081 function calls in 117.746 seconds

                      Ordered by: standard name

                      ncalls  tottime  percall  cumtime  percall filename:lineno(function)
                      333916    1.076    0.000    1.796    0.000 ind-rec.py:124(reduction_rule_5_2)
                      333912    1.514    0.000    2.336    0.000 ind-rec.py:166(reduction_rule_5_3)
                      333912    1.768    0.000    2.805    0.000 ind-rec.py:220(branching_rule_5_1)
                      331200    1.224    0.000   34.610    0.000 ind-rec.py:289(branching_rule_5_2)
                      491426    1.110    0.000   72.938    0.000 ind-rec.py:347(reduction_rule_loop)
                         301    2.008    0.007  117.582    0.391 ind-rec.py:374(inductive_recognition)
                      822630   17.871    0.000   35.732    0.000 ind-rec.py:40(p3_free)
                           1    0.164    0.164  117.746  117.746 ind-rec.py:506(case_on_20)
                      579930    3.718    0.000   33.562    0.000 ind-rec.py:6(cluster_size)
                      579930    1.431    0.000   51.005    0.000 ind-rec.py:67(valid_cluster_graph)
                      491430    1.509    0.000   67.697    0.000 ind-rec.py:79(reduction_rule_5_1)

\section{Benchmarks for \textsc{\textsc{$\Pi_A,$$\Pi_B$-Recognition} on Monopolar Graphs}}
\label{subsec:structural} %duplicate be careful

\subsection{}
\label{subsec:results} %duplicate be careful

\begin{center}
    \begin{tabu} to 0.8\textwidth { | X[l] X[l] X[c] X[c] | }
        \hline
        Graph & Time (Sec) & K & Result \\
        [0.5ex]
        \hline
        \hline
Bowtie & 0.00061182975769 & 3 & False \\
[0.3ex]
 & 0.00116783857346 & 2 & False \\
 [0.3ex]
 & 0.00140007019043 & 5 & True \\
 [0.3ex]
 \hline
$K_3$ and Claw & 0.000331211090088 & 2 & True \\
[0.3ex]
 & 0.000331621170044 & 3 & True \\
 [0.3ex]
 & 0.000334539413452 & 5 & True \\
 [0.3ex]
 \hline
$K_5$ and Claw & 0.000755069255829 & 2 & False \\
[0.3ex]
\hline
 & 0.00162389993668 & 4 & True \\
 [0.3ex]
 & 0.00161329984665 & 6 & True \\
 [0.3ex]
 \hline
From 3.1 & 0.000818741321564 & 2 & False \\
[0.3ex]
 & 0.00517585039139 & 5 & True \\
 [0.3ex]
 & 0.00514071941376 & 7 & True \\
 [0.3ex]
 \hline
Twenty & 0.0135761094093 & 5 & False \\
[0.3ex]
 & 0.40817595005 & 10 & False \\
 [0.3ex]
 & 0.834017539024 & 15 & True \\
 [0.3ex]
 \hline
\end{tabu}
\end{center}

\subsection{}
\label{subsec:results} %duplicate be careful

=== Case Bowtie ===
         287776 function calls (287775 primitive calls) in 0.142 seconds

   Ordered by: standard name

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      301    0.006    0.000    0.140    0.000 mp-part.py:17(monopolar_partition)
        1    0.002    0.002    0.142    0.142 mp-part.py:55(case_bowtie)
      903    0.001    0.000    0.006    0.000 mp-part.py:6(forbidden_graphs)

      === Case k3 + claw ===
               268543 function calls in 0.146 seconds

         Ordered by: standard name

         ncalls  tottime  percall  cumtime  percall filename:lineno(function)
            301    0.007    0.000    0.144    0.000 mp-part.py:17(monopolar_partition)
            903    0.001    0.000    0.006    0.000 mp-part.py:6(forbidden_graphs)
              1    0.002    0.002    0.146    0.146 mp-part.py:75(case_k3_plus_claw)

              === Case k5 + claw ===
                       390487 function calls in 0.185 seconds

                 Ordered by: standard name

                 ncalls  tottime  percall  cumtime  percall filename:lineno(function)
                    301    0.007    0.000    0.182    0.001 mp-part.py:17(monopolar_partition)
                    903    0.001    0.000    0.008    0.000 mp-part.py:6(forbidden_graphs)
                      1    0.003    0.003    0.185    0.185 mp-part.py:94(case_k5_plus_claw)

                      === Case From 3.1 ===
                               895859 function calls in 0.434 seconds

                         Ordered by: standard name

                         ncalls  tottime  percall  cumtime  percall filename:lineno(function)
                              1    0.006    0.006    0.434    0.434 mp-part.py:113(case_from_3_1)
                            301    0.016    0.000    0.428    0.001 mp-part.py:17(monopolar_partition)
                           2107    0.001    0.000    0.018    0.000 mp-part.py:6(forbidden_graphs)

                           === Case on 20 ===
                                    24745973 function calls in 13.509 seconds

                              Ordered by: standard name

                              ncalls  tottime  percall  cumtime  percall filename:lineno(function)
                                   1    0.312    0.312   13.509   13.509 mp-part.py:132(case_on_20)
                                 301    0.331    0.001   13.197    0.044 mp-part.py:17(monopolar_partition)
                               38227    0.027    0.000    0.539    0.000 mp-part.py:6(forbidden_graphs)

\section{Concluding remarks}
\label{sec:conclusion}
Summarize in a short paragraph the work you did. Discuss what future work and open questions ensue from your work.

\bibliographystyle{plain}
\bibliography{ref}
See the format of the attached bibliography file for referencing~\cite{ref1}.


\end{document}
